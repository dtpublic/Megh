#!/bin/bash
# DataTorrent Ingestion application CLI.
# For more info see docs on http://www.datatorrent.com/
#
# Authors: Sandeep Deshmukh (sandeep@datatorrent.com)
#          Devendra Vyavhare (devendra@datatorrent.com)
#   
# Copyright: (c) 2014 DataTorrent, Inc. All rights reserved.


# Disable filename expansion
set -f

#------------------------------------------------------------------------------
# Support functions
#------------------------------------------------------------------------------
log() { printf "%b\n" "$*"; }
info() { log "$*" ; }
warn() { log "WARNING: $*" ; }
debug() { (( ${verbose} )) && log "DEBUG: $*"; }
error() { log "\nERROR: $*\n" ; }

# Produces real directory based on input with all the links resolved
# Following http://stackoverflow.com/questions/59895/can-a-bash-script-tell-what-directory-its-stored-in
real_dir() {
  SOURCE="${1:-${BASH_SOURCE[0]}}"
  while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
    SOURCE_DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
    SOURCE="$(readlink "$SOURCE")"
    [[ $SOURCE != /* ]] && SOURCE="$SOURCE_DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
  done
  SOURCE_DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
  echo "$SOURCE_DIR"
}

#------------------------------------------------------------------------------
# Default settings
#------------------------------------------------------------------------------
fg_mode=0
service_mode=0
script_dir=$(real_dir "${BASH_SOURCE[0]}")
app_package=`find ../apps -maxdepth 1 -type f -name "dtingest-*" 2>/dev/null`
if [ -s "$app_package" ]
then
  DT_APP=$app_package
fi

# Provide instructions for using the installation script
usage(){
cat << USAGE

DataTorrent Ingestion Application

Usage:
$0 [-f filefilter] [--fastMerge] [--scanInterval scanInterval] [--originalAppId appId] [-w] [--no-recurse] [--name] [--compact] [--compactionSize] [--separator] [-e-aes] [-e-pki] [--key key] [-c-gzip] [-c-lzo] [--lzoClassName lzoClassName] [-j IngestionAppPackge] sourceURL(s) destinationURL

 -j : IngestionApp package filename
 -f : filter for reading files from input source (default=read all files)
 --name : name of the application (has to be unique amongst running apps)
 --no-recurse : disable recursive copy of input data
 --fastMerge : enable fast merge (only for HDFS output)
 --oneTimeCopy : shutdown application once copy is complete
 --scanInterval : directory scan interval in h|m|s format e.g. 10h or 10m or 10s
 --originalAppId : specify original application identifier for restart
 -w : overwrite if file exists in destination directory (default=off)
 --compact : set compaction 
 --compactionSize : compaction size in  MB|GB format e.g. 2048MB or 5GB
 --separator : separator string to be used for file boundaries
 -e-aes : Set encryption to AES
 -e-pki : Set encryption to PKI
 --key : key to be used for encryption
 -c-gzip : set compression to gzip
 -c-lzo : set compression to lzo
 --lzoClassName : Class name of LzoOutputStream, this should extend com.datatorrent.apps.ingestion.process.CompressionOutputStream class

USAGE
}


process_options() {
    while true; do
        case "$1" in
            -j|--jarfile) DT_APP=${2}; shift; shift;;
            -f|--filter) filter=${2}; shift; shift;;
            --no-recurse) recursive=false; shift;;
            --fastMerge) fastMerge=true; shift;;
            --oneTimeCopy) oneTimeCopy=true; shift;;
            --name) name=${2}; shift; shift;;
            --scanInterval) scanInterval=${2}; shift; shift;;
            --originalAppId) originalAppId=${2}; shift; shift;;
            -w|--overwrite) overwrite=true; shift;;
            --compact) compact=true; shift;;
            --compactionSize) compactionSize=${2}; shift; shift;;
            --separator) separator=${2}; shift; shift;;
            -e-aes) aes=true; shift;;
            -e-pki) pki=true; shift;;
            --key) key=${2}; shift; shift;;
            -c-gzip) gzipCompress=true; shift;;
            -c-lzo) lzoCompress=true; shift;;
            --lzoClassName) lzoClassName=${2}; shift; shift;;
            *) open_string=$open_string" "${1}; if [ "${1}" == "" ];then break; fi; shift;;
        esac
    done
}

set_relaunch_parameters() {
  inputurl="dummyUrl"
  outputurl="dummyurl"
}

check_parameters(){

# Validate input JAR
if [ "$DT_APP" == "" ]
then
    echo "Provide app file name."
    usage;
    echo ;
    exit 1 ;
fi

# parse open_string
words=( $open_string )
len="${#words[@]}"
if [ $len -gt 1 ];
then
  inputurl=${words[0]};
  outputurl=${words[$len-1]}
fi

end=$(($len-2))
for x in `seq 1 $end`;
do
    inputurl=$inputurl","${words[$x]};
done;

# Validate output URL
if [ "$outputurl" == "" ]
then
    echo "Mandatory output URL is missing. Exiting".
    usage ;
    exit 1 ;
fi

# Validate input URL
if [ "$inputurl" == "" ]
then
    echo "Mandatory input URL is missing."
    usage;
    echo ;
    exit 1 ;
fi

if [[ ! -z "$aes" && ! -z "$pki" ]]
then
  echo "Select only one encryption method at a time."
  exit 1;
fi

if [[ ! -z "$gzipCompress" && ! -z "$lzoCompress" ]]
then
  echo "Select only one compression method at a time."
  exit 1;
fi

input_protocol=`echo $inputurl | awk -F":" '{print tolower($1)}' `
output_protocol=`echo $outputurl | awk -F":" '{print tolower($1)}' `

if [ $input_protocol == "kafka" ]
then
  topic=`echo $inputurl | awk -F/ '{print $3}'`
  zookeeperlist=`echo $inputurl | awk -F/ '{print $4}'`
  if [ -z "$topic" -o -z "$zookeeperlist" ]
  then
    echo "Please provide valid input url for kafka. Valid url format: kafka://<topic>/<zookeeper-list> "
    exit 1
  fi
fi


if [ $input_protocol == "jms" ]
then
  brokerURL=`echo $inputurl | awk -F/ '{print $3}'`
  subject=`echo $inputurl | awk -F/ '{print $4}'`
  if [ -z "$subject" -o -z "$brokerURL" ]
  then
    echo "Please provide valid input url for jms. Valid url format: jms://<host>:<port>/<topic>"
    exit 1
  fi
fi

if [ $output_protocol == "kafka" ]
then
  destTopic=`echo $outputurl | awk -F/ '{print $3}'`
  destBrokerlist=`echo $outputurl | awk -F/ '{print $4}'`
  if [ -z "$destTopic" -o -z "$destBrokerlist" ]
  then
    echo "Please provide valid input url for kafka. Valid url format: kafka://<topic>/<zookeeper-list> "
    exit 1
  fi
fi


if [ $output_protocol == "jms" ]
then
  destBrokerURL=`echo $outputurl | awk -F/ '{print $3}'`
  destSubject=`echo $outputurl | awk -F/ '{print $4}'`
  if [ -z "$destSubject" -o -z "$destBrokerURL" ]
  then
    echo "Please provide valid input url for jms. Valid url format: jms://<host>:<port>/<topic>"
    exit 1
  fi
fi

if [ ! -z "$originalAppId" ]
then
  launchArgs="$launchArgs -originalAppId $originalAppId";
fi
}

parse_scantime() {
  unit=${scanInterval: -1}
  case "$unit" in
    "h") sec=`expr 60 \* 60`;
    ;;
    "m") sec=60;
    ;;
    "s") sec=1;
    ;;
    *)
      echo "Enter valid unit for scanInterval it should be in either h, m or s e.g. 10h or 10m or 10s"
      exit 1;
    ;;
  esac
  time=${scanInterval:0:${#scanInterval}-1}
  re='^[0-9]+$'
  if ! [[ $time =~ $re ]]
  then
   echo "Enter valid number for scanInterval"
   exit 1;
  fi
  totalMS=`expr $time \* $sec \* 1000`
  eval "$1"="'$totalMS'"
}

parse_compactionSize() {
  if [ -z "$compactionSize" ]
  then
    echo "Enter valid compaction size. CompactionSize is mandatory if compaction is enabled."
    exit 1;
  fi
  unit=${compactionSize: -2}
  case "$unit" in
    "MB") bytes=1;
    ;;
    "GB") bytes=1024;
    ;;
    *)
      echo "Enter valid unit for compactionSize it should be in either MB or GB e.g. 2048MB or 5GB"
      exit 1;
    ;;
  esac
  size=${compactionSize:0:${#compactionSize}-2}
  re='^[0-9]+$'
  if ! [[ $size =~ $re ]]
  then
   echo "Enter valid number for compactionSize"
   exit 1;
  fi
  totalSize=`expr $size \* $bytes`
  status=$?
  if [ $status -eq 1 ]
  then
    echo "compactionSize should be greater than 0."
    exit 1
  fi
  if [ $status -eq 2 ]
  then
    echo "Invalid input for compactionSize."
    exit 1
  fi
  if [ $status -eq 3 ]
  then
    echo "compactionSize should be less than 9223372036854775807 bytes."
    exit 1;
  fi
  eval "$1"="'$totalSize'"
}

create_xml(){

CONF_FILE=/tmp/dtingest.$MYPID;
touch $CONF_FILE;
if [ $? -ne 0 ]
then
  echo "Unable to create tmp file $CONF_FILE . Exiting."
  exit 1;
fi


cat  > $CONF_FILE << EOF
<configuration>
  <property>
    <name>dt.operator.FileSplitter.prop.scanner.files</name>
    <value>$inputurl</value>
  </property>

  <property>
    <name>dt.operator.FileMerger.prop.filePath</name>
    <value>$outputurl</value>
  </property>

EOF

if [ ! -z "$filter" ]
then
cat >> $CONF_FILE << FILTER
  <property>
    <name>dt.operator.FileSplitter.prop.scanner.filePatternRegularExp</name>
    <value>$filter</value>
  </property>
FILTER
fi

if [ ! -z "$recursive" ]
then
cat >> $CONF_FILE << RECURSIVE
  <property>
    <name>dt.operator.FileSplitter.prop.scanner.recursive</name>
    <value>$recursive</value>
  </property>
RECURSIVE
fi


if [ ! -z "$overwrite" ]
then
cat >> $CONF_FILE << OVERWRITE
  <property>
    <name>dt.operator.FileMerger.prop.overwriteOutputFile</name>
    <value>$overwrite</value>
  </property>
OVERWRITE
fi

if [ ! -z "$aes" ]
then
cat >> $CONF_FILE << AESENCRYPT
  <property>
    <name>dt.application.Ingestion.encrypt.aes</name>
    <value>$aes</value>
  </property>
AESENCRYPT
encrypt=true
fi

if [ ! -z "$pki" ]
then
cat >> $CONF_FILE << PKIENCRYPT
  <property>
    <name>dt.application.Ingestion.encrypt.pki</name>
    <value>$pki</value>
  </property>
PKIENCRYPT
encrypt=true
fi

if [ "$encrypt" = true ]
then
  if [ -z "$key" ]
  then
    echo "Enter valid encryption key for selected encryption type."
    exit 1;
  fi
cat >> $CONF_FILE << PASSKEY
  <property>
    <name>dt.application.Ingestion.encrypt.key</name>
    <value>$key</value>
  </property>
PASSKEY
fi

if [ ! -z "$gzipCompress" -o ! -z "$lzoCompress" ]
then
cat >> $CONF_FILE << COMPRESS
  <property>
    <name>dt.application.Ingestion.compress</name>
    <value>true</value>
  </property>
COMPRESS
fi

if [ ! -z "$gzipCompress" ]
then
cat >> $CONF_FILE << GZCOMPRESS
  <property>
    <name>dt.application.Ingestion.compress.type</name>
    <value>gzip</value>
  </property>
GZCOMPRESS
fi

if [ ! -z "$lzoCompress" ]
then
  if [ -z "$lzoClassName" ]
  then
    echo "Enter class name for lzoOuputStream implementation"
    exit 1;
  fi
cat >> $CONF_FILE << LZOCOMPRESS
  <property>
    <name>dt.application.Ingestion.compress.type</name>
    <value>lzo</value>
  </property>
  <property>
    <name>dt.application.Ingestion.compress.lzo.className</name>
    <value>$lzoClassName</value>
  </property>
LZOCOMPRESS
fi

if [ ! -z "$compact" ]
then
parse_compactionSize compactSize
cat >> $CONF_FILE << COMPACT
  <property>
    <name>output.compact</name>
    <value>$compact</value>
  </property>
  <property>
    <name>output.rolling_file_size</name>
    <value>$compactSize</value>
  </property>
  <property>
    <name>output.compact_separator</name>
    <value>$separator</value>
  </property>
  <property>
    <name>dt.operator.FileMerger.filePath</name>
    <value>$outputurl</value>
  </property>
COMPACT
fi

case $input_protocol in 
    "kafka")
    cat >> $CONF_FILE << KAFKA
  <property>
    <name>dt.application.Ingestion.operator.MessageReader.prop.topic</name>
    <value>$topic</value>
  </property>
  <property>
    <name>dt.application.Ingestion.operator.MessageReader.prop.zookeeper</name>
    <value>$zookeeperlist</value>
  </property>
  <property>
    <name>dt.application.Ingestion.operator.FileWriter.prop.filePath</name>
    <value>$outputurl</value>
  </property>
KAFKA
;;
    "jms")
    cat >> $CONF_FILE << JMS
  <property>
    <name>dt.application.Ingestion.operator.MessageReader.prop.connectionFactoryProperties.brokerURL</name>
    <value>tcp://$brokerURL</value>
  </property>
  <property>
    <name>dt.application.Ingestion.operator.MessageReader.prop.ackMode</name>
    <value>AUTO_ACKNOWLEDGE</value>
  </property>
  <property>
    <name>dt.application.Ingestion.operator.MessageReader.prop.subject</name>
    <value>$subject</value>
  </property>
  <property>
    <name>dt.application.Ingestion.operator.FileWriter.prop.filePath</name>
    <value>$outputurl</value>
  </property>
JMS
;;

    "hdfs")
cat >>  $CONF_FILE << HDFS
  <property>
    <name>dt.operator.FileSplitter.prop.scanner.ignoreFilePatternRegularExp</name>
    <value>.*\._COPYING_</value>
  </property>
HDFS
;;
    
esac # end of case statement for input_protocol

if [ "$output_protocol" == "kafka" ]
then
cat >> $CONF_FILE << OUTPUTKAFKA
    <property>
        <name>dt.application.Ingestion.operator.MessageWriter.prop.topic</name>
        <value>$destTopic</value>
    </property>
    <property>
        <name>dt.application.Ingestion.operator.MessageWriter.prop.configProperties(metadata.broker.list)</name>
        <value>$destBrokerlist</value>
    </property>
OUTPUTKAFKA
fi

if [ "$output_protocol" == "jms" ]
then
cat >> $CONF_FILE << OUTPUTJMS
 <property>
    <name>dt.application.Ingestion.operator.MessageWriter.prop.connectionFactoryProperties.brokerURL</name>
    <value>tcp://$destBrokerURL</value>
  </property>
  <property>
    <name>dt.application.Ingestion.operator.MessageWriter.prop.ackMode</name>
    <value>AUTO_ACKNOWLEDGE</value>
  </property>
  <property>
    <name>dt.application.Ingestion.operator.MessageWriter.prop.subject</name>
    <value>$destSubject</value>
  </property>
OUTPUTJMS
fi


if [ ! -z "$input_protocol" ]
then
cat >>  $CONF_FILE << INPUTPROTOCOL
  <property>
    <name>dt.operator.BlockReader.prop.scheme</name>
    <value>$input_protocol</value>
  </property>
INPUTPROTOCOL
fi

cat >> $CONF_FILE << OUTPUTPROTOCOL
  <property>
    <name>dt.output.protocol</name>
    <value>$output_protocol</value>
  </property>
OUTPUTPROTOCOL

if [ ! -z "$fastMerge" ]
then
cat >> $CONF_FILE << FASTMERGE
  <property>
    <name>dt.output.enableFastMerge</name>
    <value>$fastMerge</value>
  </property>
FASTMERGE
fi

if [ ! -z "$oneTimeCopy" ]
then
cat >> $CONF_FILE << ONETIMECOPY
  <property>
    <name>dt.input.oneTimeCopy</name>
    <value>$oneTimeCopy</value>
  </property>
ONETIMECOPY
fi


if [ ! -z "$scanInterval" ]
then
parse_scantime interval
if [[ $? != 0 ]]
then
  exit 1;
fi
cat >> $CONF_FILE << EOF
  <property>
    <name>dt.operator.FileSplitter.prop.scanner.scanIntervalMillis</name>
    <value>$interval</value>
  </property>
EOF
fi

if [ ! -z "$name" ]
then
cat >> $CONF_FILE << NAME
  <property>
    <name>dt.application.Ingestion.attr.APPLICATION_NAME</name>
    <value>Ingestion-$name</value>
  </property>
NAME
fi



echo "</configuration>" >> $CONF_FILE 
}


launch_app() {
  # Search for Ingestion application name. This needs to move to setupDtIngestEnv() when that is integrated with the script.
  DT_INGESTION_APP=${DT_INGESTION_APP:=Ingestion}
  echo ;
  echo ;
  echo "Launching app..."
  echo launch -conf $CONF_FILE $launchArgs $DT_APP -exactMatch $DT_INGESTION_APP ;
  if [ ! -z "$DTINGEST_TEST_MODE" ]
  then
    # Test  mode will only create the conf file and will skip launching the app.
    # Used for testing dtingest script (internal, not exposed to the users)
    exit 0;
  else
    if [ -f ${script_dir}/dtcli ]
    then
      echo launch -conf $CONF_FILE $launchArgs $DT_APP -exactMatch $DT_INGESTION_APP | ${script_dir}/dtcli
    else
      echo launch -conf $CONF_FILE $launchArgs $DT_APP -exactMatch $DT_INGESTION_APP | dtcli
    fi
  fi
  if [ $? != 0 ]
  then
    echo "Error running Ingestion App. Exiting...";
  fi
}



#------------------------------------------------------------------------------
# Process user input and execute requested action
#------------------------------------------------------------------------------
# Confirm at at least one argument was provided
if [ -z $1 ]; then
  usage;
  exit 1;
fi

script_opts="$@"

# Process remaining action options
process_options ${script_opts}
if [ ! -z "$originalAppId" ]
then
  set_relaunch_parameters
fi
check_parameters

MYPID=$BASHPID;

create_xml

launch_app

# Revert filename expansion changes.
set +f
